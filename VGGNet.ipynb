{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0034575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:30<00:00, 5.65MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary as summary_\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "                                \n",
    "trainset = torchvision.datasets.CIFAR10(root='/data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform)\n",
    "                                       \n",
    "train_loader = DataLoader(trainset,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "test_loader = DataLoader(testset,\n",
    "                         batch_size=100,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb694b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.modules.dropout import Dropout\n",
    "\n",
    "# VGG model definition\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        # Initialize the VGG model with the specified configuration\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            # Cifar-10 Size = 32x32  \n",
    "            nn.Linear(512*1*1, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(1000, num_classes)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out   \n",
    "    \n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1), \n",
    "                        nn.BatchNorm2d(x),   \n",
    "                        nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "net = VGG('VGG19').to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c89a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                        lr=1e-4, \n",
    "                                        betas=(0.9, 0.999),\n",
    "                                        eps=1e-08,\n",
    "                                        weight_decay=0,\n",
    "                                        amsgrad=False)\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        current_correct = (predicted == labels).sum().item()\n",
    "        correct += current_correct\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current batch average train accuracy:', current_correct / labels.size(0))\n",
    "            print('Current batch average train loss:', loss.item() / labels.size(0))\n",
    "\n",
    "    print('\\nTotal average train accuarcy:', correct / total)\n",
    "    print('Total average train loss:', train_loss / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6823bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'vgg19_cifar10.pth'\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, labels).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('\\nTotal average test accuarcy:', correct / total)\n",
    "    print('Total average test loss:', loss / total)\n",
    "\n",
    "    state = {\n",
    "        'net' : net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cdc3d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.1015625\n",
      "Current batch average train loss: 0.009116468951106071\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.453125\n",
      "Current batch average train loss: 0.005762543994933367\n",
      "\n",
      "Total average train accuarcy: 0.43818\n",
      "Total average train loss: 0.005811328899860382\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Total average test accuarcy: 0.5066\n",
      "Total average test loss: 0.0142610999584198\n",
      "Model Saved!\n",
      "\tTime elapsed: 520.558355808258\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.5859375\n",
      "Current batch average train loss: 0.004273262806236744\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.640625\n",
      "Current batch average train loss: 0.003753699827939272\n",
      "\n",
      "Total average train accuarcy: 0.65752\n",
      "Total average train loss: 0.0037744594764709473\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Total average test accuarcy: 0.6281\n",
      "Total average test loss: 0.011188747859001159\n",
      "Model Saved!\n",
      "\tTime elapsed: 966.9134242534637\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.6796875\n",
      "Current batch average train loss: 0.003537624143064022\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.74609375\n",
      "Current batch average train loss: 0.0026644086465239525\n",
      "\n",
      "Total average train accuarcy: 0.74766\n",
      "Total average train loss: 0.002844500234127045\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Total average test accuarcy: 0.6875\n",
      "Total average test loss: 0.009182535588741303\n",
      "Model Saved!\n",
      "\tTime elapsed: 1399.597333908081\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.7890625\n",
      "Current batch average train loss: 0.0024438246618956327\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.796875\n",
      "Current batch average train loss: 0.0022385637275874615\n",
      "\n",
      "Total average train accuarcy: 0.8103\n",
      "Total average train loss: 0.0021685598057508467\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Total average test accuarcy: 0.7175\n",
      "Total average test loss: 0.008613513785600662\n",
      "Model Saved!\n",
      "\tTime elapsed: 1828.6057946681976\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.80078125\n",
      "Current batch average train loss: 0.002163745928555727\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.85546875\n",
      "Current batch average train loss: 0.0015719712246209383\n",
      "\n",
      "Total average train accuarcy: 0.86024\n",
      "Total average train loss: 0.0016246440172195435\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Total average test accuarcy: 0.7217\n",
      "Total average test loss: 0.008902133148908616\n",
      "Model Saved!\n",
      "\tTime elapsed: 2264.973582983017\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.89453125\n",
      "Current batch average train loss: 0.0013972268206998706\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.91015625\n",
      "Current batch average train loss: 0.0012699863873422146\n",
      "\n",
      "Total average train accuarcy: 0.894\n",
      "Total average train loss: 0.0012341873851418495\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Total average test accuarcy: 0.7212\n",
      "Total average test loss: 0.00999149831533432\n",
      "Model Saved!\n",
      "\tTime elapsed: 2711.773726940155\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.94921875\n",
      "Current batch average train loss: 0.0008905173745006323\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.88671875\n",
      "Current batch average train loss: 0.0012190546840429306\n",
      "\n",
      "Total average train accuarcy: 0.92004\n",
      "Total average train loss: 0.000926773709654808\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Total average test accuarcy: 0.713\n",
      "Total average test loss: 0.011129574203491211\n",
      "Model Saved!\n",
      "\tTime elapsed: 3154.253863811493\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.94921875\n",
      "Current batch average train loss: 0.0006111256661824882\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.93359375\n",
      "Current batch average train loss: 0.0008898930973373353\n",
      "\n",
      "Total average train accuarcy: 0.93804\n",
      "Total average train loss: 0.0007287152107059955\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Total average test accuarcy: 0.7405\n",
      "Total average test loss: 0.009873441481590271\n",
      "Model Saved!\n",
      "\tTime elapsed: 4113.275182723999\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.96484375\n",
      "Current batch average train loss: 0.0003966066869907081\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.9453125\n",
      "Current batch average train loss: 0.0006885832990519702\n",
      "\n",
      "Total average train accuarcy: 0.95048\n",
      "Total average train loss: 0.0005885933057963848\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Total average test accuarcy: 0.7435\n",
      "Total average test loss: 0.010136129999160767\n",
      "Model Saved!\n",
      "\tTime elapsed: 5136.551785945892\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current batch average train accuracy: 0.984375\n",
      "Current batch average train loss: 0.00037266549770720303\n",
      "\n",
      "Current batch: 100\n",
      "Current batch average train accuracy: 0.953125\n",
      "Current batch average train loss: 0.00046700527309440076\n",
      "\n",
      "Total average train accuarcy: 0.95912\n",
      "Total average train loss: 0.00048295030929148197\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Total average test accuarcy: 0.7438\n",
      "Total average test loss: 0.011028928977251053\n",
      "Model Saved!\n",
      "\tTime elapsed: 5755.319210767746\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    print('\\tTime elapsed:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7192f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
